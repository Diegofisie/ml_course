{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML Course, Bogota, Columbia  (&copy; Josh Bloom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../talktools.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.evernote.com/l/AUVOiUntlxZHM60VXN8WZWzg83pzEIL-XJwB/image.png\" width=\"50%\">\n",
    "\n",
    "Building Trees Rigorously (Node Splitting Criteria)\n",
    "\n",
    "<img src=\"https://www.evernote.com/l/AUVA6K4mqnhOMoNcy93La3lFe5XOAxgaWrUB/image.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collections of Trees (\"Decision Forests\", \"Random Forests\")\n",
    "\n",
    "<img src=\"https://contentmamluswest001.blob.core.windows.net/content/14b2744cf8d6418c87ffddc3f3127242/9502630827244d60a1214f250e3bbca7/b729c21014a34955b20fa94dc13390e5/image\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying NIST Handwritten Digits\n",
    "\n",
    "We will try to classify handwritten digits (0-9) from their raw pixelated images.\n",
    "\n",
    "Each image is 8 $\\times$ 8 pixels.  We will not do any feature extraction and instead classify based on the intensity values for each pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, metrics\n",
    "# import NIST digits data set (1797 8x8 images)\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "f,axs = plt.subplots(1,10,figsize=(16, 6))\n",
    "objarr = np.empty_like(axs)\n",
    "for n, ax in enumerate(axs.flat):\n",
    "    objarr.flat[n] = ax.imshow(digits['images'][n], cmap='gray', interpolation='nearest')\n",
    "    ax.get_xaxis().set_ticks([])\n",
    "    ax.get_yaxis().set_ticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Now we split the data into a training and testing set.}$\n",
    "\n",
    "$\\textbf{We will only fit the classifier on the training set and use the testing set to evaluate performance.}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the first 500 as training\n",
    "train = 500\n",
    "Xtr = digits['data'][:train]\n",
    "Ytr = digits['target'][:train]\n",
    "print(\"training size: \" + str(len(Ytr)))\n",
    "\n",
    "# testing set\n",
    "Xte = digits['data'][train:]\n",
    "Yte = digits['target'][train:]\n",
    "print(\"testing size: \" + str(len(Yte)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a classifier: \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# instantiate classifier object\n",
    "classifier = RandomForestClassifier(n_estimators=50)\n",
    "\n",
    "# fit the classification model on training set\n",
    "classifier.fit(Xtr, Ytr)\n",
    "\n",
    "# make predictions for testing set\n",
    "pred_rf = classifier.predict(Xte) \n",
    "\n",
    "print(\"True Class / Predicted class\")\n",
    "print(np.vstack((Yte[0:10],pred_rf[0:10])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://cs.stanford.edu/people/karpathy/svmjs/demo/demoforest.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Estimation\n",
    "\n",
    "Q: What evaluation metrics are available?\n",
    "\n",
    "<b>Loss Functions</b>\n",
    "\n",
    "- `metrics.zero_one(y_true, y_pred)`\n",
    "Zero-One classification loss\n",
    "- `metrics.hinge_loss(y_true, pred_decision[, ...])`\n",
    "Cumulated hinge loss (non-regularized).\n",
    "- `metrics.mean_square_error(y_true, y_pred)`\n",
    "Mean square error regression loss\n",
    "\n",
    "<b>Score Functions</b>\n",
    "\n",
    "- `metrics.zero_one_loss(y_true, y_pred)`\n",
    "Zero-One classification score\n",
    "- `metrics.auc(x, y)`\n",
    "Compute Area Under the Curve (AUC)\n",
    "- `metrics.precision_score(y_true, y_pred[, ...])`\n",
    "Compute the precision\n",
    "- `metrics.recall_score(y_true, y_pred[, pos_label])`\n",
    "Compute the recall\n",
    "- `metrics.fbeta_score(y_true, y_pred, beta[, ...])`\n",
    "Compute fbeta score\n",
    "- `metrics.f1_score(y_true, y_pred[, pos_label])`\n",
    "Compute f1 score\n",
    "\n",
    "<b>Evaluation Plots</b>\n",
    "- `metrics.confusion_matrix(y_true, y_pred[, ...])` Compute confusion matrix to evaluate the accuracy of a classification\n",
    "- `metrics.roc_curve(y_true, y_score)` Compute Receiver operating characteristic (ROC)\n",
    "- `metrics.precision_recall_curve(y_true, ...)` Compute precision-recall pairs for different probability thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute zero-one loss / score & confusion matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "rf_01 = metrics.zero_one_loss(Yte, pred_rf) # zero-one loss\n",
    "rf_01_score = metrics.accuracy_score(Yte, pred_rf) # zero-one score\n",
    "rf_confmat = metrics.confusion_matrix(Yte, pred_rf) # conf mat\n",
    "\n",
    "print(\"Zero-One Loss: \" + str(rf_01))\n",
    "print(\"Zero-One Score: \" + str(rf_01_score))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(\"[i, j] is the # of objects truly in group i but predicted to be in group j\")\n",
    "print(rf_confmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(rf_confmat, annot=True,  fmt='', \n",
    "            xticklabels=[str(x) for x in range(10)], yticklabels=[str(x) for x in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot some digits that we get wrong\n",
    "wrong = np.where(pred_rf != Yte)[0][:9]\n",
    "\n",
    "f,axs = plt.subplots(3,3,figsize=(7, 7))\n",
    "objarr = np.empty_like(axs)\n",
    "\n",
    "for n, ax in enumerate(axs.flat):\n",
    "    objarr.flat[n] = ax.imshow(np.reshape(Xte[wrong[n]],(8,8)).astype(int),\n",
    "                              cmap='gray_r', interpolation='nearest')\n",
    "    ax.grid(False)\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.yaxis.set_visible(False)\n",
    "    ax.set_title(\"True = \" + str(int(Yte[wrong[n]])) +\". Pred = \" + str(int(pred_rf[wrong[n]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute precision and recall\n",
    "# Note: precision & recall are for 2-class; multi-class returns weighted avg. prec/recall\n",
    "\n",
    "rf_precision = metrics.precision_score(Yte, pred_rf,average=\"weighted\") # TP / (TP + FP)\n",
    "rf_recall = metrics.recall_score(Yte, pred_rf,average=\"weighted\") # TP / (TP + FN)\n",
    "\n",
    "print(\"Avg. Precision: \",rf_precision)\n",
    "print(\"Avg. Recall: \", rf_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ROC curve, AUC for RF classifier using digit = 1\n",
    "digit = 1\n",
    "Yte_1 = list(map(lambda x: x == digit and 1. or 0.,Yte)) # does Y = digit\n",
    "\n",
    "pred_rf_prob = classifier.predict_proba(Xte) \n",
    "\n",
    "pred_rf_prob_1 = pred_rf_prob[:,digit]\n",
    "fpr, tpr, thresholds = metrics.roc_curve(Yte_1, pred_rf_prob_1)\n",
    "\n",
    "f, ax = plt.subplots(1,1,figsize=(5, 5))\n",
    "ax.plot(fpr,tpr,'b-',linewidth=3)\n",
    "ax.set_xlim([0.,0.3])\n",
    "ax.set_ylim([0.6,1.0005])\n",
    "ax.set_xlabel(\"False Positive Rate\",size=15)\n",
    "ax.set_ylabel(\"True Positive Rate\",size=15)\n",
    "ax.set_title(\"ROC Curve for NIST digit={} RF Classifier\".format(digit),size=22)\n",
    "print(\"AUC for digit={}: \".format(digit) + str(metrics.auc(fpr,tpr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Tuning the Classifier}$  \n",
    "======================================================\n",
    "\n",
    "For now we have used an RF classifier with the choice of `n_estimators` and the default parameters.\n",
    "\n",
    "Q: How do I choose which model and (hyper) parameters to use?\n",
    "\n",
    " - KNN with what # of neighbors?\n",
    " - SVM which what kernel & bandwidth?\n",
    " - RF with how many estimators and which max_features?\n",
    " - GP with what kernel & bandwidth?\n",
    " \n",
    "**Solution: use `grid_search.GridSearchCV`**:\n",
    "`grid_search.GridSearchCV(estimator, param_grid, loss_func, n_jobs, cv=None)`\n",
    "\n",
    "Computes cv-fold cross-validated loss_func (or score_func) of estimator over a param_grid on n_jobs cores, and returns the best model!\n",
    "\n",
    "Let's see how we can rigorously find the optimal model using cross-validation and grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best Random Forest classifier\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s %(levelname)s %(message)s')\n",
    "\n",
    "\n",
    "# explore 3 different forest sizes and 3 choices of mtry\n",
    "parameters = {'n_estimators':[20,50,100],  'max_features':[8,10,'auto'], \n",
    "             'criterion': ['gini','entropy']}\n",
    "rf_tune = model_selection.GridSearchCV(RandomForestClassifier(), parameters, \n",
    "                                   n_jobs = -1, cv = 5,verbose=1)\n",
    "rf_opt = rf_tune.fit(Xtr, Ytr)\n",
    "\n",
    "print(\"Best zero-one score: \" + str(rf_opt.best_score_) + \"\\n\")\n",
    "print(\"Optimal Model:\\n\" + str(rf_opt.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_opt.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Towards interpretability\n",
    "\n",
    "Which features are important in my model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "feature_importances = rf_opt.best_estimator_.feature_importances_\n",
    "feature_importances = feature_importances.reshape(8,8)\n",
    "print(feature_importances.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(feature_importances, cmap=plt.cm.viridis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**sklearn FRE**\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html\n",
    "\n",
    "Feature ranking with recursive feature elimination.\n",
    "\n",
    "Given an external estimator that assigns weights to features (e.g., the coefficients of a linear model), the goal of recursive feature elimination (RFE) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through a coef_ attribute or through a feature_importances_ attribute. Then, the least important features are pruned from current set of features. That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFE(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "  n_features_to_select=1, step=1, verbose=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import datasets\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "X = digits['data']\n",
    "Y = digits['target']\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "rfe = RFE(estimator=clf, n_features_to_select=1, step=1)\n",
    "rfe.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a16fb31d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "ranking = rfe.ranking_.reshape(digits.images[0].shape)\n",
    "sns.heatmap(ranking, cmap=plt.cm.viridis_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** LightGBM **\n",
    "\n",
    "A fast gradient boosting framework that uses tree-based learning algorithm, generally useful for \"big\" datasets (say 10k rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on a mac: brew install libomp\n",
    "# !conda install -c conda-forge lightgbm graphviz -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jbloom/anaconda3/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "try:\n",
    "    # To enable interactive mode you should install ipywidgets\n",
    "    # https://github.com/jupyter-widgets/ipywidgets\n",
    "    from ipywidgets import interact, SelectMultiple\n",
    "    INTERACTIVE = True\n",
    "except ImportError:\n",
    "    INTERACTIVE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/microsoft/LightGBM/blob/master/examples/regression/regression.train?raw=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/microsoft/LightGBM/blob/master/examples/regression/regression.test?raw=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000 (7000, 28)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('regression.train?raw=true', header=None, sep='\\t')\n",
    "df_test = pd.read_csv('regression.test?raw=true', header=None, sep='\\t')\n",
    "\n",
    "y_train = df_train[0]\n",
    "y_test = df_test[0]\n",
    "X_train = df_train.drop(0, axis=1)\n",
    "X_test = df_test.drop(0, axis=1)\n",
    "print(len(y_train), X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dataset object for LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_test = lgb.Dataset(X_test, y_test, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'num_leaves': 5,\n",
    "    'metric': ['l1', 'l2'],\n",
    "    'verbose': -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttraining's l2: 0.217995\ttraining's l1: 0.457448\tvalid_1's l2: 0.21641\tvalid_1's l1: 0.456464\n",
      "[20]\ttraining's l2: 0.205099\ttraining's l1: 0.436869\tvalid_1's l2: 0.201616\tvalid_1's l1: 0.434057\n",
      "[30]\ttraining's l2: 0.197421\ttraining's l1: 0.421302\tvalid_1's l2: 0.192514\tvalid_1's l1: 0.417019\n",
      "[40]\ttraining's l2: 0.192856\ttraining's l1: 0.411107\tvalid_1's l2: 0.187258\tvalid_1's l1: 0.406303\n",
      "[50]\ttraining's l2: 0.189593\ttraining's l1: 0.403695\tvalid_1's l2: 0.183688\tvalid_1's l1: 0.398997\n",
      "[60]\ttraining's l2: 0.187043\ttraining's l1: 0.398704\tvalid_1's l2: 0.181009\tvalid_1's l1: 0.393977\n",
      "[70]\ttraining's l2: 0.184982\ttraining's l1: 0.394876\tvalid_1's l2: 0.178803\tvalid_1's l1: 0.389805\n",
      "[80]\ttraining's l2: 0.1828\ttraining's l1: 0.391147\tvalid_1's l2: 0.176799\tvalid_1's l1: 0.386476\n",
      "[90]\ttraining's l2: 0.180817\ttraining's l1: 0.388101\tvalid_1's l2: 0.175775\tvalid_1's l1: 0.384404\n",
      "[100]\ttraining's l2: 0.179171\ttraining's l1: 0.385174\tvalid_1's l2: 0.175321\tvalid_1's l1: 0.382929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jbloom/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is [21]\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "/Users/jbloom/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:762: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    }
   ],
   "source": [
    "evals_result = {}  # to record eval results for plotting\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=100,\n",
    "                valid_sets=[lgb_train, lgb_test],\n",
    "                feature_name=['f' + str(i + 1) for i in range(X_train.shape[-1])],\n",
    "                categorical_feature=[21],\n",
    "                evals_result=evals_result,\n",
    "                verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_metric(metric_name):\n",
    "    ax = lgb.plot_metric(evals_result, metric=metric_name, figsize=(10, 5))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "393495e5e9944ec18ea07321537ee852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(Dropdown(description='metric_name', options=('l1', 'l2'), value='l1'), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if INTERACTIVE:\n",
    "    # create widget to switch between metrics\n",
    "    interact(render_metric, metric_name=params['metric'])\n",
    "else:\n",
    "    render_metric(params['metric'][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot feature importances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_plot_importance(importance_type, max_features=10,\n",
    "                           ignore_zero=True, precision=4):\n",
    "    ax = lgb.plot_importance(gbm, importance_type=importance_type,\n",
    "                             max_num_features=max_features,\n",
    "                             ignore_zero=ignore_zero, figsize=(12, 8),\n",
    "                             precision=precision)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab9503ee5baf41398439ad1f5a69e19c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(Dropdown(description='importance_type', options=('split', 'gain'), value='split'), IntSlider(value=10, description='max_features', max=28, min=1), Checkbox(value=True, description='ignore_zero'), IntSlider(value=4, description='precision', max=10), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if INTERACTIVE:\n",
    "    # create widget for interactive feature importance plot\n",
    "    interact(render_plot_importance,\n",
    "             importance_type=['split', 'gain'],\n",
    "             max_features=(1, X_train.shape[-1]),\n",
    "             precision=(0, 10))\n",
    "else:\n",
    "    render_plot_importance(importance_type='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_tree(tree_index, show_info, precision=4):\n",
    "    show_info = None if 'None' in show_info else show_info\n",
    "    return lgb.create_tree_digraph(gbm, tree_index=tree_index,\n",
    "                                   show_info=show_info, precision=precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92ae74abe2754441b8d1d1b7113f2df2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(IntSlider(value=49, description='tree_index', max=99), SelectMultiple(description='show_info', index=(0,), options=('None', 'split_gain', 'internal_value', 'internal_count', 'leaf_count'), value=('None',)), IntSlider(value=4, description='precision', max=10), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if INTERACTIVE:\n",
    "    # create widget to switch between trees and control info in nodes\n",
    "    interact(render_tree,\n",
    "             tree_index=(0, gbm.num_trees() - 1),\n",
    "             show_info=SelectMultiple(  # allow multiple values to be selected\n",
    "                 options=['None',\n",
    "                          'split_gain',\n",
    "                          'internal_value',\n",
    "                          'internal_count',\n",
    "                          'leaf_count'],\n",
    "                 value=['None']),\n",
    "             precision=(0, 10))\n",
    "    tree = None\n",
    "else:\n",
    "    tree = render_tree(84, ['None'])\n",
    "tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
