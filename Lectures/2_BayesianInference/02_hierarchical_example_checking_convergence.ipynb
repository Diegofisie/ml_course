{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML Course, Bogota, Columbia  (&copy; Josh Bloom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "\n",
       ".rendered_html\n",
       "{\n",
       "  color: #2C5494;\n",
       "  font-family: Ubuntu;\n",
       "  font-size: 140%;\n",
       "  line-height: 1.1;\n",
       "  margin: 0.5em 0;\n",
       "  }\n",
       "\n",
       ".talk_title\n",
       "{\n",
       "  color: #498AF3;\n",
       "  font-size: 250%;\n",
       "  font-weight:bold;\n",
       "  line-height: 1.2; \n",
       "  margin: 10px 50px 10px;\n",
       "  }\n",
       "\n",
       ".subtitle\n",
       "{\n",
       "  color: #386BBC;\n",
       "  font-size: 180%;\n",
       "  font-weight:bold;\n",
       "  line-height: 1.2; \n",
       "  margin: 20px 50px 20px;\n",
       "  }\n",
       "\n",
       ".slide-header, p.slide-header\n",
       "{\n",
       "  color: #498AF3;\n",
       "  font-size: 200%;\n",
       "  font-weight:bold;\n",
       "  margin: 0px 20px 10px;\n",
       "  page-break-before: always;\n",
       "  text-align: center;\n",
       "  }\n",
       "\n",
       ".rendered_html h1\n",
       "{\n",
       "  color: #498AF3;\n",
       "  line-height: 1.2; \n",
       "  margin: 0.15em 0em 0.5em;\n",
       "  page-break-before: always;\n",
       "  text-align: center;\n",
       "  }\n",
       "\n",
       "\n",
       ".rendered_html h2\n",
       "{ \n",
       "  color: #386BBC;\n",
       "  line-height: 1.2;\n",
       "  margin: 1.1em 0em 0.5em;\n",
       "  }\n",
       "\n",
       ".rendered_html h3\n",
       "{ \n",
       "  font-size: 100%;\n",
       "  line-height: 1.2;\n",
       "  margin: 1.1em 0em 0.5em;\n",
       "  }\n",
       "\n",
       ".rendered_html li\n",
       "{\n",
       "  line-height: 1.8;\n",
       "  }\n",
       "\n",
       ".input_prompt, .CodeMirror-lines, .output_area\n",
       "{\n",
       "  font-family: Consolas;\n",
       "  font-size: 120%;\n",
       "  }\n",
       "\n",
       ".gap-above\n",
       "{\n",
       "  padding-top: 200px;\n",
       "  }\n",
       "\n",
       ".gap01\n",
       "{\n",
       "  padding-top: 10px;\n",
       "  }\n",
       "\n",
       ".gap05\n",
       "{\n",
       "  padding-top: 50px;\n",
       "  }\n",
       "\n",
       ".gap1\n",
       "{\n",
       "  padding-top: 100px;\n",
       "  }\n",
       "\n",
       ".gap2\n",
       "{\n",
       "  padding-top: 200px;\n",
       "  }\n",
       "\n",
       ".gap3\n",
       "{\n",
       "  padding-top: 300px;\n",
       "  }\n",
       "\n",
       ".emph\n",
       "{\n",
       "  color: #386BBC;\n",
       "  }\n",
       "\n",
       ".warn\n",
       "{\n",
       "  color: red;\n",
       "  }\n",
       "\n",
       ".center\n",
       "{\n",
       "  text-align: center;\n",
       "  }\n",
       "\n",
       ".nb_link\n",
       "{\n",
       "    padding-bottom: 0.5em;\n",
       "}\n",
       "\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c2b53cda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run ../talktools.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Bayesian Inference for the Mining Disaster Data Set\n",
    "\n",
    "<img src=\"imgs/mining.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An **exponential** is usually a good choice for a parameter that can have any positive value $z$\n",
    "\n",
    "$$\n",
    "Z = {\\rm Exp}(\\lambda) = P(z|\\lambda) = \\lambda e^{-\\lambda}\n",
    "$$\n",
    "\n",
    "The expectation value is:\n",
    "\n",
    "$$\n",
    "E[Z | \\lambda ] = 1/\\lambda\n",
    "$$\n",
    "\n",
    "The **Poission** Distribution is usually a good choice for an outcome that can have any positive integer value $k$:\n",
    "\n",
    "$$\n",
    "Z = {\\rm Poi}(\\lambda) = P(k|\\lambda) = \\frac{\\lambda^k e^{-k}}{k!}\n",
    "$$\n",
    "\n",
    "The expectation value is:\n",
    "\n",
    "$$\n",
    "E[Z | \\lambda] = \\lambda\n",
    "$$\n",
    "\n",
    "cf. https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/blob/master/Chapter1_Introduction/Ch1_Introduction_PyMC3.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "sns.set_context(\"talk\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.linspace(0, 4, 100)\n",
    "expo = stats.expon\n",
    "lambda_ = [0.5, 1]\n",
    "\n",
    "for l, c in zip(lambda_, [\"r\",\"b\"]):\n",
    "    plt.plot(a, expo.pdf(a, scale=1./l), lw=3,\n",
    "             color=c, label=\"$\\lambda = %.1f$\" % l)\n",
    "    plt.fill_between(a, expo.pdf(a, scale=1./l), color=c, alpha=.33)\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel(\"PDF at $z$\")\n",
    "plt.xlabel(\"$z$\")\n",
    "plt.ylim(0,1.2)\n",
    "plt.title(\"Probability density function of an Exponential random variable;\\\n",
    " differing $\\lambda$\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(16)\n",
    "poi = stats.poisson\n",
    "lambda_ = [1, 4]\n",
    "colours = [\"r\",\"b\"]\n",
    "\n",
    "plt.bar(a, poi.pmf(a, lambda_[0]), color=colours[0],\n",
    "        label=\"$\\lambda = %.1f$\" % lambda_[0], alpha=0.60,\n",
    "        edgecolor=colours[0], lw=\"3\")\n",
    "\n",
    "plt.bar(a, poi.pmf(a, lambda_[1]), color=colours[1],\n",
    "        label=\"$\\lambda = %.1f$\" % lambda_[1], alpha=0.60,\n",
    "        edgecolor=colours[1], lw=\"3\")\n",
    "\n",
    "plt.xticks(a + 0.4, a)\n",
    "plt.legend()\n",
    "plt.ylabel(\"probability of $k$\")\n",
    "plt.xlabel(\"$k$\")\n",
    "plt.title(\"Probability mass function of a Poisson random variable; differing \\\n",
    "$\\lambda$ values\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"imgs/mining1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import theano\n",
    "theano.__version__,  pm.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disasters/year from 1850-1960\n",
    "disasters = np.array([4, 5, 4, 0, 1, 4, 3, 4, 0, 6, 3, 3, 4, 0, 2, 6, 3, 3, 5,\n",
    "                      4, 5, 3, 1, 4, 4, 1, 5, 5, 3, 4, 2, 5, 2, 2, 3, 4, 2, 1,\n",
    "                      3, 2, 2, 1, 1, 1, 1, 3, 0, 0, 1, 0, 1, 1, 0, 0, 3, 1, 0,\n",
    "                      3, 2, 2, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 2, 1, 0, 0, 0,\n",
    "                      1, 1, 0, 2, 3, 3, 1, 1, 2, 1, 1, 1, 1, 2, 4, 2, 0, 0, 1,\n",
    "                      4, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1])\n",
    "N = len(disasters)\n",
    "t = np.arange(1850, 1850 + N)\n",
    "# Generate random test data for comparison\n",
    "#disasters = np.random.poisson(size=N, lam=2.)\n",
    "plt.plot(t, disasters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model for annual coal mining disaster rates with a changepoint $\\tau$:\n",
    "\n",
    "$$D_t \\sim \\text{Poisson}\\left(\\begin{cases}\n",
    "\\mu_1 & t \\leq \\tau \\\\\n",
    "\\mu_2 & t > \\tau\n",
    "\\end{cases}\n",
    "\\right)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    # Specify priors for tau, mu_1, mu_2\n",
    "    tau = pm.DiscreteUniform('tau', lower=t.min(), upper=t.max())\n",
    "    mu = pm.Exponential('mu', lam=np.array([1., 1.]), shape=2)\n",
    "\n",
    "    # Poisson likelihood function for observed data\n",
    "    mu_1_or_2 = pm.Deterministic('mu_1_or_2', pm.math.switch(t < tau, mu[0], mu[1]))\n",
    "    D = pm.Poisson('D', mu_1_or_2, observed=disasters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    step = pm.NUTS()\n",
    "    trace = pm.sample(20000, step=step, njobs=2)\n",
    "    \n",
    "burned_in = trace[5000:]\n",
    "thinned = burned_in[::10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the posterior\n",
    "We can get an idea of the behavior of our Markov chain by viewing the trace of one of the variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(thinned['tau'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can obtain summary statistics from the MCMC easily\n",
    "pm.stats.summary(thinned,  varnames=['mu', \"tau\"]) #summary statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pymc3` also has its own built-in plotting functionality which helps quickly visualize the distribution of the variables of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable trace summary plots\n",
    "pm.plots.traceplot(trace=thinned, varnames=['mu'], figsize=(12, 4));\n",
    "plt.legend(['mu_1', 'mu_2'])\n",
    "\n",
    "pm.plots.traceplot(trace=thinned, varnames=['tau']);\n",
    "plt.legend(['tau'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed posterior distribution plots\n",
    "pm.plots.plot_posterior(trace=thinned['mu'][:, 0], range=(0.0, 4.5), figsize=(6,6));\n",
    "pm.plots.plot_posterior(trace=thinned['mu'][:, 1], range=(0.0, 4.5), figsize=(6,6));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autocorrelation plots give a rough idea of how close to i.i.d the samples from our posterior distribution are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full chain (no burn-in or thinning)\n",
    "pm.plots.autocorrplot(trace=trace, varnames=['tau', 'mu']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain with 5000 burn-in iterations\n",
    "pm.plots.autocorrplot(trace=burned_in, varnames=['tau', 'mu']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain with 5000 burn-in iterations, thinned by 10x\n",
    "pm.plots.autocorrplot(trace=thinned, varnames=['tau', 'mu']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also make inferences about the values of other functions/transformations of the parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior distribution of change in mean (mu_2 - mu_1)\n",
    "change = thinned['mu'][:, 1] - thinned['mu'][:, 0]\n",
    "ci = np.floor(0.975 * len(change))\n",
    "plt.hist(change);\n",
    "plt.title('Change in the rate: {:1.3f} (± {:1.3f})'.format(\n",
    "          np.mean(change), np.abs(np.percentile(change, 2.5) - np.percentile(change, 97.5)) / 2));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(thinned[:][\"mu\"][:,1], thinned[:][\"mu\"][:,0],alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and we can also plot realizations of the model from the posterior!\n",
    "plt.figure(figsize=(12, 10))\n",
    "realizations = pm.sample_ppc(thinned, model=model, samples=3)\n",
    "for D_i in realizations['D']:\n",
    "    plt.plot(t, D_i, '-o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can plot realizations of the model from the posterior!\n",
    "dates = np.arange(1850,1961)\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "plt.plot(t, disasters,'o-')\n",
    "plt.xlim([1850,1960])\n",
    "plt.xlabel('Year',fontsize=20)\n",
    "plt.ylabel('# of Disasters',fontsize=20)\n",
    "\n",
    "# plot first 250 MCMC samples\n",
    "for i in np.arange(250):\n",
    "    ri = thinned[i][\"mu_1_or_2\"]\n",
    "    plt.plot(dates,ri,'-r',alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.stats.quantiles(thinned, qlist=[2.5, 50, 95])[1][\"mu\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence Diagnostics\n",
    "\n",
    "Determining whether an MCMC has converged can be difficult, especially in high-dimensional parameter spaces \n",
    "\n",
    "A number of diagnostics (both formal and informal) exist, and many of these are available in PyMC in `pm.diagnostics` (https://docs.pymc.io/api/diagnostics.html), e.g.:\n",
    "- Geweke score: compares mean of beginning of chain with mean of end\n",
    "- Gelman-Rubin: compare variance between chains to variance of single chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geweke score = $\\frac{\\bar{\\theta}_e - \\bar{\\theta}_b}{\\sqrt{Var(\\theta_e) + Var(\\theta_b)}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Geweke score for tau: should lie between -1 and 1\n",
    "plt.plot(pm.geweke(trace['tau'])[:, 1], 'o')\n",
    "plt.axhline(1, c='red')\n",
    "plt.axhline(-1, c='red')\n",
    "plt.gca().margins(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.diagnostics.gelman_rubin(thinned['mu'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **First check** - start multiple chains from different starting values and see that they converge to the same place\n",
    "- **More formal methods** - Raftery-Lewis, Geweke, autocorrelation, etc. \n",
    "- **Goodness of fit** Posterior Predictive Checks which simulate data from your fitted model and compare to the observed data (checks convergence AND the suitability of the chosen model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other MCMC Code on the Market\n",
    "\n",
    "- WinBUGS, OpenBUGS - Bayesian inference Using Gibbs Sampling JAGS - Just Another Gibbs Sampler (C++)\n",
    "\n",
    "- in R -\n",
    "mcmc, rbugs, BRugs, MCMCpack, adaptMCMC, rjags, etc. See rpy2 (http://rpy.sourceforge.net/rpy2.html)\n",
    "\n",
    "- in Python -\n",
    "   - bayesian-inference (http://code.google.com/p/bayesian-inference/) \n",
    "   - emcee (http://danfm.ca/emcee/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What about Bayesian Approaches to Machine Learning?\n",
    "\n",
    "- Many of the “Bayesian” ML approaches (e.g., Naive Bayes, Bayes Nets) are usually applied in a Frequentist way\n",
    "    - “prior” probabilities are estimated with MLE instead of assigning probability distributions (e.g., Dirichlet)\n",
    "\n",
    "- There are lots of great non-parametric Bayes approaches (many of which are being developed here at UCB!)\n",
    "   - Gaussian processes (priors over smooth functions)\n",
    "   - Dirichlet processes (priors over allocation of objects to classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
